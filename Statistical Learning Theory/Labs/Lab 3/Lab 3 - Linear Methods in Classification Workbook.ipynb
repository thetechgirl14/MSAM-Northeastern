{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models in Classification\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, we're going to look at linear models in classification. In lecture, we considered three methods of fitting linear decision boundaries: fit by __regression__, fit by __estimating labels by a Gaussian distributions__, and fit by __logistic regression__. \n",
    "\n",
    "We will start by testing out our models for binary classification on the UW Breast Cancer data set. This dataset contains a series of measurements derived from pictures of cells and attempts to classify them as cancerous or not, based on their numerical characteristics. \n",
    "\n",
    "<table>\n",
    "    <tr><td>\n",
    "        <img src=\"http://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/cancer_images/92_7241.gif\" width=300px>\n",
    "        </td><td width=200px>\n",
    "            $$\\Rightarrow \\{\\text{Malignant, Benign}\\}$$\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "We will then apply multilabel classification techniques to the MNIST handwriting dataset. The MNIST dataset contains pictures of hand written digits, and attempts to classify them. In MNIST, the feature space is high dimensional while the label space is relatively low, and will serve as a bench mark for many of our later machine learning techniques. \n",
    "\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr><td>\n",
    "        <img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\" width=300px>\n",
    "        </td>\n",
    "        </td><td width=20px>\n",
    "            $$\\Rightarrow$$\n",
    "        </td>\n",
    "        <td width=40px>\n",
    "        <table><tr><td>0</td></tr><tr><td>1</td></tr><tr><td>2</td></tr><tr><td>3</td></tr>\n",
    "        <tr><td>4</td></tr><tr><td>5</td></tr><tr><td>6</td></tr><tr><td>7</td></tr><tr><td>8</td></tr>\n",
    "            <tr><td>9</td></tr>\n",
    "        </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "\n",
    "Cancer cells grow more chaotically than their benign counterparts. Their growth tends to be unstable, nonlinear and  ruptured. (See http://sphweb.bumc.bu.edu/otlt/MPH-Modules/PH/PH709_Cancer/PH709_Cancer7.html)\n",
    "<img src=\"http://sphweb.bumc.bu.edu/otlt/MPH-Modules/PH/PH709_Cancer/Characteristics%20of%20Cancer%20Cells.png\" width=400px>\n",
    "The UW Breast Cancer Dataset (https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)) contains hand measured characteristics of cells as a training set and their diagnosis as _benign_ or _malignant_. \n",
    "\n",
    "<table><tr><td>\n",
    "    <img src = \"http://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/cancer_images/91_5691.gif\" width = 300>\n",
    "    </td><td>\n",
    "    <img src = \"http://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/cancer_images/92_7241.gif\" width = 300>\n",
    "    </td>\n",
    "</tr></table>\n",
    "\n",
    "The data set contains\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.<br><br>\n",
    "\n",
    "Number of instances: 569 <br><br>\n",
    "\n",
    "Number of attributes: 32 (ID, diagnosis, 30 real-valued input features)<br><br>\n",
    "\n",
    "Attribute Information:<br><br>\n",
    "\n",
    "1) ID number<br>\n",
    "2) Diagnosis (M = malignant, B = benign)<br>\n",
    "\n",
    "\n",
    "3-32) Ten real-valued features are computed for each cell nucleus:<br><br>\n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter)<br>\n",
    "b) texture (standard deviation of gray-scale values)<br>\n",
    "c) perimeter<br>\n",
    "d) area<br>\n",
    "e) smoothness (local variation in radius lengths)<br>\n",
    "f) compactness (perimeter^2 / area - 1.0)<br>\n",
    "g) concavity (severity of concave portions of the contour)<br>\n",
    "h) concave points (number of concave portions of the contour)<br>\n",
    "i) symmetry<br>\n",
    "j) fractal dimension (\"coastline approximation\" - 1)<br><br>\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names\n",
    "</div>\n",
    "\n",
    "It doesn't say this very well in the documentation, but the first set of 10 features numbers in each row is the __mean__ property for all the cells in the image. The second set of 10 features is the __standard error__ and the third is the \"__worst__\", or most extreme. \n",
    "\n",
    "We start by downloading the data and the names of the columns. Note that the datafile itself is just a list of number, so we need to download the names file separately and merge the dataframes.\n",
    "\n",
    "For an excellent kernel on data visualization for the UWBCD, take a look here: https://www.kaggle.com/kanncaa1/feature-selection-and-data-visualization. \n",
    "\n",
    "See also Seaborn's documentation on plotting categorical data: https://seaborn.pydata.org/tutorial/categorical.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data')\n",
    "names = [\"id\",\"diagnosis\",\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\n",
    "         \"smoothness_mean\",\"compactness_mean\",\"concavity_mean\",\"concave_points_mean\",\n",
    "         \"symmetry_mean\",\"fractal_dimension_mean\",\"radius_se\",\"texture_se\",\"perimeter_se\",\n",
    "         \"area_se\",\"smoothness_se\",\"compactness_se\",\"concavity_se\",\"concave\" \"points_se\",\n",
    "         \"symmetry_se\",\"fractal_dimension_se\",\"radius_worst\",\"texture_worst\",\n",
    "         \"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\",\n",
    "         \"concavity_worst\",\"concave_points_worst\",\"symmetry_worst\",\"fractal_dimension_worst\"]\n",
    "\n",
    "data.columns=names\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis for Categorical Targets\n",
    "\n",
    "Lets start with an exploratory analysis. First, we see that __diagnosis__ is our target variable and __id__ should be dropped. Let generate a few questions for our exploratory analysis:\n",
    "\n",
    "* What does the data look like for each feature?\n",
    "* What is the proportion of __malignant__ to __benign__ samples?\n",
    "* What does the correlation matrix look like for mean, standard error and worst?\n",
    "* Can we visualize the data in a useful way, as violin plots, box plots or swarm plots? As scatter plots?\n",
    "\n",
    "To start, lets use the DataFrame classes built in `DataFrame.describe()` function:\n",
    "\n",
    "* `DataFrame.describe()` returns the __count__, __mean__, __std__, __min__, __max__ and __quantiles__ for all columns of the dataframe. [Doc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split off diagnosis, and normalize the data into units of standard deviation from the mean. Recall that data frame objects have the following:\n",
    "\n",
    "\n",
    "* `DataFrame.count` Count number of non-NA/null observations.\n",
    "* `DataFrame.max` Maximum of the values in the object.\n",
    "* `DataFrame.min` Minimum of the values in the object.\n",
    "* `DataFrame.mean` Mean of the values.\n",
    "* `DataFrame.std` Standard deviation of the obersvations.\n",
    "* `DataFrame.select_dtypes` Subset of a DataFrame including/excluding columns based on their dtype. \n",
    "* `DataFrame.drop(columns=[])` Drop a list of columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop Feature Columns X\n",
    "X = data.drop(columns=[\"id\",\"diagnosis\"])\n",
    "\n",
    "## Set Up Target Variables y\n",
    "y = data[\"diagnosis\"]\n",
    "\n",
    "## Normalize feature data by centering on the mean and dividing by std\n",
    "X = (X - X.mean())/X.std()\n",
    "\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proportion of Malignant to Benign\n",
    "\n",
    "The proportion of malignant labels to benign labels can be computed using `DataFrame.value_counts()` and displayed using seaborns `sns.countplot()` [Doc](https://seaborn.pydata.org/generated/seaborn.countplot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(y.value_counts())\n",
    "sns.countplot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M,B = y.value_counts()\n",
    "print(\"Roughly \",M/(M+B),\"malignant to\",B/(M+B),\"benign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Matrix\n",
    "\n",
    "Dataframes have a built in correlation matrix function, `DataFrame.corr()` and we can use seaborn to plot the heatmap with \n",
    "\n",
    "* `sns.heatmap(matrix, annot=True,linewidth=.5, fmt='.1f')` The heat map of a matrix `matrix`, annotated by the Pearsons coefficient, with lines between the boxes and format of the labels set to `.1f`, that is \"Floating point notation truncated at 1 decimal place.\" For more about string formatting see for example [A Python 3 string formatting guide](https://www.programiz.com/python-programming/methods/string/format).\n",
    "\n",
    "Lets first look at all of the correlations together, and then the correlations between the __mean__, __standard error__ and __worst__ parameters individually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've set up vectors to select features for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\n",
    "         \"smoothness_mean\",\"compactness_mean\",\"concavity_mean\",\"concave_points_mean\",\n",
    "         \"symmetry_mean\",\"fractal_dimension_mean\"]\n",
    "ses = [\"radius_se\",\"texture_se\",\"perimeter_se\",\n",
    "         \"area_se\",\"smoothness_se\",\"compactness_se\",\"concavity_se\",\"concave\" \"points_se\",\n",
    "         \"symmetry_se\",\"fractal_dimension_se\"]\n",
    "worsts = [\"radius_worst\",\"texture_worst\",\n",
    "         \"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\",\n",
    "         \"concavity_worst\",\"concave_points_worst\",\"symmetry_worst\",\"fractal_dimension_worst\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(X[means].corr(),annot=True,linewidth=.5, fmt='.1f')\n",
    "\n",
    "ax.set_title(\"Correlation Among Means\",fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No real surprises here from a geometric standpoint. Could there be a difference between the mean correlations for malignant and benign? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axes = plt.subplots(1,2,figsize=(20, 8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the heat maps above are not at the same scale. We can set the minimum and maximum for the colorbar, we just need to get the min and mix correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_m = y==\"M\"\n",
    "I_b = y==\"B\"\n",
    "\n",
    "\n",
    "print(\"Min:\", vmin, \", Max:\", vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,axes = plt.subplots(1,2,figsize=(20, 8))\n",
    "I_m = y==\"M\"\n",
    "I_b = y==\"B\"\n",
    "\n",
    "sns.heatmap(X[means][I_m].corr(),annot=True,linewidth=.5, fmt='.1f',ax=axes[0],vmin=vmin,vmax=vmax)\n",
    "sns.heatmap(X[means][I_b].corr(),annot=True,linewidth=.5, fmt='.1f',ax=axes[1],vmin=vmin,vmax=vmax)\n",
    "\n",
    "axes[0].set_title(\"Correlation for Malignant\",fontsize = 20)\n",
    "axes[1].set_title(\"Correlation for Benign\",fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean is now much less correlated with the mean number of concave points. We don't need to guess, we can make this precise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "\n",
    "\n",
    "ax.set_title(\"Correlation Difference Between Malignant and Benign\",fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Plotting\n",
    "\n",
    "### Box, Violin and Swarm Plots\n",
    "\n",
    "Box, violin and swarm plots are all ways of trying to get a handle on the difference in feature distribution between the malignant and benign cells. A violin plot displays the conditional distributions next to each other for easy visual comparison. \n",
    "\n",
    "<img src=\"https://seaborn.pydata.org/_images/seaborn-violinplot-4.png\">\n",
    "\n",
    "The violin function works a little differently than other functions we have used. It takes a whole dataframe as an object and then asks us to specify which column contains the categories we want along the x-axis, which column contains the data whose distribution we want summarized, and finally which column contains the information about how the data should be labeled. \n",
    "\n",
    "* `sns.violinplot(x=, y=, hue=, data=data, split=True, inner=\"quart\")` Here, split dtermins weather we will have split violins (as above) or side by side symmetric violins. The `inner = quart` line displays the quartiles one the violin plot. \n",
    "\n",
    "`sns.violinplot` really wants to see the data displayed in the following way:\n",
    "\n",
    "|Color Label|X Category|Y Value|\n",
    "|-----|--------|-----|\n",
    "|(Smoker)|(Days)|(Tip Amount)|\n",
    "|Yes| Sun| 5.40|\n",
    "|No | Fri| 1.27|\n",
    "|Yes| Sat| 4.41|\n",
    "|Yes| Sat| 7.88|\n",
    "\n",
    "\n",
    "\n",
    "For example, the code \n",
    "\n",
    "`sns.violinplot(x=\"diagnosis\", y=\"radius_mean\", hue=\"diagnosis\", data=data, split=True, inner=\"quart\")`\n",
    "\n",
    "produces a violin plot for the variable __radius_mean__ colored by __diagnosis__. The include of `x=\"diagnosis\"` indicates that on the $x$-axis we will be splitting the data up by the diagnosis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's an annoying feature but if we want to make a single violin like we see above we have to include a dummy category vector `x=`, where all of the category are the same.  A simple way to do this is to just pass all 1's to the category vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display all of the features side by side, we have to create a new dataframe of the form \n",
    "\n",
    "|Color Label|X Category|Y Value|\n",
    "|-----|--------|-----|\n",
    "|(diagnosis)|(Feature Name)|(Value)|\n",
    "|B| radius_mean| 2.13|\n",
    "|B| radius_mean| 1.27|\n",
    "|M| radius_mean|-1.49|\n",
    "|$\\vdots$| $\\vdots$| $\\vdots$|\n",
    "|B| area_mean| -1.32|\n",
    "|M| area_mean| 0.41|\n",
    "\n",
    "To do this, we use the `pandas.melt` function to flatten the dataframe into one long $3\\times 30N$ data frame where the first column is the diagnosis, the second column is the corresponding feature and the third column is the value. First, we concatenate `y` back onto `X` and then we melt it to the proper form. \n",
    "\n",
    "* `pandas.melt(DataFrame, id_var=,var_name=,value_name)` Returns a dataframe of identifier varaibles while all other columns, considered measured variables (value_vars), are \"unpivoted\" to the row axis, leaving just two non-identifier columns, `variable` and `value` (to quote the documentation). [Doc.](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.melt.html)\n",
    "\n",
    "For us, diagnosis will be the identifier variable, and we call the column of variable names \"features\" and the column of values \"value\". The violin plot is then give by letting the features (read: the variable names) run along the $x$-axis, the feature values be collected on the $y$-axis and the colors be determined by __diagnosis__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "vio = pd.concat([y,X[means]],axis=1)\n",
    "vio = pd.melt(vio,id_vars=\"diagnosis\",\n",
    "                    var_name=\"features\",\n",
    "                    value_name='value')\n",
    "\n",
    "sns.violinplot(x=\"features\", y=\"value\", hue=\"diagnosis\", data=vio,split=True, inner=\"quart\")\n",
    "\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is quiet a large difference for quite a few of the variables, including __radius_mean__, __area_mean__, __concave_points_mean__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box plots\n",
    "\n",
    "Box plots, like violin plots, compare the differences in distributions for different labels, but they do it in a more numerical way.\n",
    "\n",
    "<img width=600px src=\"https://cdn-images-1.medium.com/max/1600/1*2c21SkzJMf3frPXPAR_gZA.png\"> [Source](https://towardsdatascience.com/understanding-boxplots-5e2df7bcbd51)\n",
    "\n",
    "Here, __Q1__ is the first quartile boundary, so 25% of the data have values less than __Q1__. The inner line is the __median__ and __Q3__ is the third quartile boundary, so 75% of the data have values less than __Q3__.\n",
    "\n",
    "The `seaborn.boxplot` function uses exactly the same syntax as the `seaborn.violinplot` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "\n",
    "\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like __concave_points_mean__ is really starting to emerge as a favorite for indicating cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swarm Plots\n",
    "\n",
    "A swarm plot is a representation of all of the data in your dataset in a set of nonoverlapping points. It gives a quick visual of how the points are distributed in a relative fashion. \n",
    "\n",
    "As before `sns.swarmplot` uses the same syntax as `sns.violinplot`, so once we done the work to melt our data along categories we can use seaborn to view it many different ways. \n",
    "\n",
    "Swarm plot may take a second to run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression for Binary Classifiers\n",
    "\n",
    "Run the code below if you need to reload the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data')\n",
    "names = [\"id\",\"diagnosis\",\"radius_mean\",\"texture_mean\",\"perimeter_mean\",\"area_mean\",\n",
    "         \"smoothness_mean\",\"compactness_mean\",\"concavity_mean\",\"concave_points_mean\",\n",
    "         \"symmetry_mean\",\"fractal_dimension_mean\",\"radius_se\",\"texture_se\",\"perimeter_se\",\n",
    "         \"area_se\",\"smoothness_se\",\"compactness_se\",\"concavity_se\",\"concave\" \"points_se\",\n",
    "         \"symmetry_se\",\"fractal_dimension_se\",\"radius_worst\",\"texture_worst\",\n",
    "         \"perimeter_worst\",\"area_worst\",\"smoothness_worst\",\"compactness_worst\",\n",
    "         \"concavity_worst\",\"concave_points_worst\",\"symmetry_worst\",\"fractal_dimension_worst\"]\n",
    "\n",
    "data.columns=names\n",
    "\n",
    "\n",
    "## Drop Feature Columns X\n",
    "X = data.drop(columns=[\"id\",\"diagnosis\"])\n",
    "\n",
    "## Set Up Target Variables y\n",
    "y = data[\"diagnosis\"]\n",
    "\n",
    "## Normalize feature data by centering on the mean and dividing by std\n",
    "X = (X - X.mean())/X.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now begin the actual fitting. For visual simplicity, lets first just consider fitting to two variables, __radius_mean__ and __concavity_mean__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "plt.plot(X[\"radius_mean\"][I_m],X[\"concavity_mean\"][I_m],'o',label=\"Malignant\")\n",
    "\n",
    "## We set alpha=.5 to try to avoid masking, but some points still will be burried. \n",
    "plt.plot(X[\"radius_mean\"][I_b],X[\"concavity_mean\"][I_b],'o',label=\"Benign\",alpha=.5)\n",
    "\n",
    "plt.xlabel(\"radius_mean\",fontsize=20)\n",
    "plt.ylabel(\"concavity_mean\",fontsize=20)\n",
    "plt.legend(fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Vector Encoding.\n",
    "\n",
    "We need to encode `y` as a one-hot vector. That is, we assign each label to a positional vector. In this case, let\n",
    "\n",
    "|Label|Vector|\n",
    "|-----|------|\n",
    "|B|[1,0]|\n",
    "|M|[0,1]|\n",
    "\n",
    "There are two ways to do this: using built in tool kit and by hand. We will use pandas built in tools here, in the exercise you will proceed by hand. \n",
    "\n",
    "* `pd.get_dummies(y)` Converts categorical variables into dummy index variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Using Sklearn\n",
    "\n",
    "We then perform regression using sci-kit learn. The code below will reload the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "\n",
    "print(\"The r^2 score on the training data is %.3f\"%(lr.score(X_train,y_train),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the parameter and plot the decision boundary. As usual, let $(x_i,y_i)$ be our training data and let $y_i\\in \\{0,\\ldots, k-1\\}$ in keeping with Pythons convention of labeling from 0. From one perspective, we've fit two linear functions using linear regression\n",
    "\n",
    "$$\n",
    "y_B = y_0 \\approx f_0(X) = {\\beta}_{0,0} +  X_1{\\beta}_{1,0} + X_2{\\beta}_{2,0}\\,\\hspace{3em} \n",
    "y_M = y_1 \\approx f_1(X) = {\\beta}_{0,1} +  X_1{\\beta}_{1,1} + X_2{\\beta}_{2,1}\n",
    "$$\n",
    "\n",
    "We recover a categorical fit by selecting $\\hat y_i =  \\underset{k}{\\text{argmax}} (\\hat{f}_k(x_i))$. \n",
    "\n",
    "To find the decision boundary, we just need to find where $\\hat{f}_0(X) = \\hat{f}_1(X)$. Since these are linear functions, it is easy to solve for the hyperplane\n",
    "\n",
    "$$\n",
    "X_2 = \\frac{(\\hat{\\beta}_{1,1}-\\hat{\\beta}_{1,0})X_1 + \\hat{\\beta}_{0,1} - \\hat {\\beta}_{0,0}}{\\hat{\\beta}_{1,0}-\\hat{\\beta}_{1,1}}\\,.\n",
    "$$\n",
    "\n",
    "In fact, $\\hat f_0 = -\\hat f_1$ for two label linear regression (__exercise__) so we could just solve $\\hat f_0 = 0$, but for multilabel classification this is what generalizes. \n",
    "\n",
    "Extracting the $\\beta$ values from the fit using `lr.coef_` and `lr.intercept_` we can plot the decision boundary on the scatter plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B0 = lr.intercept_\n",
    "B = lr.coef_\n",
    "\n",
    "print(\"The Linear Coefficients:\\n\", B)\n",
    "print(\"The Intercept:\", B0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make a plot of the decision regions. To do this we construct a dense grid of points an use the fit linear classifier to predict the label for each point. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Side note: It is important to remember that although in mathematical plotting $x$ runs from left to right and $y$ runs from bottom to top, in __plotting__ we often use the matrix convention, that is the top left corner of the matrix is the top left pixel, bottom right corner of the matrix is the bottom right pixel. This means that if a matrix is indexed by $(i,j)$, $i$ increases from left to right, but $j$ increases from _top to bottom_. It's because of this convention that meshgrid below returns what it does. Keep this in mind when plotting with matrices. \n",
    "</div>\n",
    "\n",
    "We will use the `np.meshgrid` function to generate the grid of points:\n",
    "\n",
    "* `XX, YY = np.meshgrid(XRange, YRange)` - Given a vector $x = (x_1,\\ldots, x_n)$ of values `XRange` and a vector $y = (y_1,\\ldots, y_m)$ of values `YRange`, meshgrid constructs all of the pairs $(x_i,y_j)$ and returns two $m\\times n$ matrices: `XX` containing the $x$ coordinates of the pairs and `YY` containing the $y$ coordinates of the pairs.\n",
    "\n",
    "For example, if $x = [1,3,4]$ and $y = [2,5]$, meshgrid will return\n",
    "$$\n",
    "XX = \\left[\n",
    "\\begin{matrix}\n",
    "1&3&4\n",
    "\\\\\n",
    "1&3&4\n",
    "\\end{matrix}\n",
    "\\right]\n",
    "\\,,\\,\\,\\,\n",
    "YY = \\left[\n",
    "\\begin{matrix}\n",
    "2&2&2\n",
    "\\\\\n",
    "5&5&5\n",
    "\\end{matrix}\n",
    "\\right]\\,.\n",
    "$$\n",
    "\n",
    "Practically, this means that $(x_i,y_j) = (XX[j,i],YY[j,i])$. The index reversal is occurs because the second component of `XX` and `YY` parameterizes the horizontal directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shows how you can use meshgrid to generate predictions for a dense grid of values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "X1 = X[\"radius_mean\"]\n",
    "X2 = X[\"concavity_mean\"]\n",
    "\n",
    "plt.plot(X1[I_m],X2[I_m],'o',label=\"Malignant\",alpha=.5)\n",
    "plt.plot(X1[I_b],X2[I_b],'o',label=\"Benign\",alpha=.5)\n",
    "\n",
    "\n",
    "## We want to make a nice clean line directly across the graph as it was before\n",
    "## The best way to do this is to find the limits of the graph and plot using them \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## We also may also want to color in the side of the decicion boundry we're\n",
    "## Labeling each point. One way to do this is using a mesh grid, and then using\n",
    "## an indexon the equation from before\n",
    "\n",
    "\n",
    "\n",
    "## We now reset the x and y limits to make sure our view is centered tightly\n",
    "## around the data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Linear) Quadratic Discriminant Analysis (QDA)\n",
    "\n",
    "Recall that in quadratic discriminant analysis, we assume a Gaussian distribution for each label\n",
    "\n",
    "$$\n",
    "y_k \\approx f_k(X) = \\big[(2\\pi)^p |\\mathbf{\\Sigma}| \\big]^{-\\frac12}\\exp\\left(\\,-\\frac12(x-\\mu_k)^T\\mathbf{\\Sigma}^{-1}(x-\\mu_k)  \\,\\right)\\,,\n",
    "$$\n",
    "\n",
    "Where $\\mu$ is the center of the label distribution, $\\mathbf{\\Sigma}$ is the covariance matrix. The discriminant functions are then quadratic, and given by \n",
    "\n",
    "$$\n",
    "\\delta_k(x) = -\\frac12\\log|\\mathbf{\\Sigma}_k| - \\frac12 (x-\\mu_k)^T\\mathbf{\\Sigma}_k^{-1}(x-\\mu_k) + \\log \\pi_k\\,.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Sci-kit learn has a QDA library, but if you need to you can estimate the parameters by <br><br>\n",
    "$\\hat \\pi_k = N_k/N$, where $N_k$ is the number of observations of $k$. Stored in `qda.priors_`. <br>\n",
    "$\\hat\\mu_k  = \\frac{1}{N_k}\\sum_{y_i = k} x_i$ is the mean of $k$ observations. Stored in `qda.means_`.<br>\n",
    "$\\hat{\\mathbf{\\Sigma}} = \\frac{1}{N-K}\\sum_{k=1}^K\\sum_{y_i=k}||x_i - \\hat \\mu_k||^2$ estimates covariance. Stored in `qda.covariance_`.<br>\n",
    "</div>\n",
    "\n",
    "Using sci-kit learn's `QuadraticDiscriminantAnalysis` class from the `discriminant_analysis` library, we can fit the function as before. You can use the code below to compute the linear decision boundary by just changing the function call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "print(\"Score: %.3f\"%qda.score(X_train,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to do a lot better than regression, but can we trust it? Indeed, this is scoring itself using a different metric to regression. Regression uses least squares while QDA used mean accuracy (mean number of correct prediction). \n",
    "\n",
    "__Question:__ Which score would you expect regression to the best with respect to, the $r^2$ score or the mean accuracy?\n",
    "\n",
    "We will now use fit object's `predict` function to generate the background labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "X1 = X[\"radius_mean\"]\n",
    "X2 = X[\"concavity_mean\"]\n",
    "\n",
    "plt.plot(X1[I_m],X2[I_m],'o',label=\"Malignant\")\n",
    "plt.plot(X1[I_b],X2[I_b],'o',label=\"Benign\",alpha=.5)\n",
    "\n",
    "## As before we generate a meshgrid, but now we use qda.predict to guess at the label. \n",
    "\n",
    "xm,xM = plt.xlim()\n",
    "ym,yM = plt.ylim()\n",
    "\n",
    "XX, YY = np.meshgrid(np.linspace(xm,xM, 100),np.linspace(ym,yM, 100)) \n",
    "\n",
    "## We now form a 10000x2 array of the (x,y) coordiantes for each point by reshaping\n",
    "## the XX and YY matricies and pasting them together. We need to feed a Nx2 vector\n",
    "## into the qda.predict function, otherwise it will think we have too many features.\n",
    "## We can reshape it later to get our grid back\n",
    "\n",
    "grid=np.concatenate([XX.reshape(-1,1),YY.reshape(-1,1)],axis=1)\n",
    "\n",
    "ZZ = qda.predict(grid).reshape(XX.shape)  ## We predict, and reshape back to the origional grid\n",
    "\n",
    "z1 = ZZ == 'M'\n",
    "z2 = ZZ == 'B'\n",
    "\n",
    "plt.plot(XX[z1],YY[z1],',',color=\"C0\")\n",
    "plt.plot(XX[z2],YY[z2],',',color=\"C1\")\n",
    "\n",
    "## We now reset the x and y limits to make sure our view is centered tightly\n",
    "## around the data. \n",
    "\n",
    "plt.xlabel(\"radius_mean\",fontsize=20)\n",
    "plt.ylabel(\"concavity_mean\",fontsize=20)\n",
    "plt.legend(fontsize=15)\n",
    "\n",
    "ax.set_xlim([xm, xM])\n",
    "ax.set_ylim([ym, yM])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the decision boundary for QDA is more difficult than in the linear case. If you are interested in a well worked out example the official documentation has one here: https://scikit-learn.org/stable/auto_examples/classification/plot_lda_qda.html#sphx-glr-auto-examples-classification-plot-lda-qda-py\n",
    "\n",
    "#### Exercise:\n",
    "\n",
    "Write a formula for the QDA decision boundary in terms of the mean, prior, and covariance. Implement your formula in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear discriminant analysis\n",
    "\n",
    "Compare the above the LDA here below. We have only changed two things: First, we call `LinearDiscriminantAnalysis` instead of quadratic and second we have added the discriminant line from the regression analysis in. Notice that both match up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "qda = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "qda.fit(X_train, y)\n",
    "\n",
    "print(\"Score: %.3f\"%qda.score(X_train,y))\n",
    "\n",
    "f, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "X1 = X[\"radius_mean\"]\n",
    "X2 = X[\"concavity_mean\"]\n",
    "\n",
    "plt.plot(X1[I_m],X2[I_m],'o',label=\"Malignant\")\n",
    "plt.plot(X1[I_b],X2[I_b],'o',label=\"Benign\",alpha=.5)\n",
    "\n",
    "## As before we generate a meshgrid, but now we use qda.predict to guess at the label. \n",
    "\n",
    "xm,xM = plt.xlim()\n",
    "ym,yM = plt.ylim()\n",
    "\n",
    "XX, YY = np.meshgrid(np.linspace(xm,xM, 100),np.linspace(ym,yM, 100)) \n",
    "\n",
    "## We now form a 10000x2 array of the (x,y) coordiantes for each point by reshaping\n",
    "## the XX and YY matricies and pasting them together. We need to feed a Nx2 vector\n",
    "## into the qda.predict function, otherwise it will think we have too many features.\n",
    "## We can reshape it later to get our grid back\n",
    "\n",
    "grid=np.concatenate([XX.reshape(-1,1),YY.reshape(-1,1)],axis=1)\n",
    "\n",
    "ZZ = qda.predict(grid).reshape(XX.shape)  ## We predict, and reshape back to the origional grid\n",
    "\n",
    "z1 = ZZ == 'M'\n",
    "z2 = ZZ == 'B'\n",
    "\n",
    "plt.plot(XX[z1],YY[z1],',',color=\"C0\")\n",
    "plt.plot(XX[z2],YY[z2],',',color=\"C1\")\n",
    "\n",
    "plt.plot(u,v,label=\"Decision Boundary\",color=\"black\")\n",
    "\n",
    "## We now reset the x and y limits to make sure our view is centered tightly\n",
    "## around the data. \n",
    "\n",
    "plt.xlabel(\"radius_mean\",fontsize=20)\n",
    "plt.ylabel(\"concavity_mean\",fontsize=20)\n",
    "plt.legend(fontsize=15)\n",
    "\n",
    "ax.set_xlim([xm, xM])\n",
    "ax.set_ylim([ym, yM])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "The logistic regression classifier has logistic discriminant functions\n",
    "\n",
    "$$\n",
    "y_j \\approx \\mathbb{P}(G=j|X=x) = \\frac{\\exp(\\beta_{j,0}+x^T\\beta_j)}{1+\\sum_{\\ell=1}^{K-1}\\exp(\\beta_{\\ell,0} + x^T\\beta_\\ell)}\\,,\\hspace{1em} \\forall j=1,\\ldots, K-1\\,,\n",
    "$$\n",
    "and \n",
    "$$\n",
    "y_K \\approx \\mathbb{P}(G=K|X=x)  = \\frac{1}{1+\\sum_{\\ell=1}^{K-1}\\exp(\\beta_{\\ell,0} + x^T\\beta_\\ell)}\\,.\n",
    "$$\n",
    "\n",
    "Again, sci-kit learn has a built in classifier in `sklearn.linear_model`, the `LogisticRegression` class [Doc](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "print(\"Score: %.3f\"%clf.score(X_train,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "X1 = X[\"radius_mean\"]\n",
    "X2 = X[\"concavity_mean\"]\n",
    "\n",
    "plt.plot(X1[I_m],X2[I_m],'o',label=\"Malignant\")\n",
    "plt.plot(X1[I_b],X2[I_b],'o',label=\"Benign\",alpha=.5)\n",
    "\n",
    "## As before we generate a meshgrid, but now we use qda.predict to guess at the label. \n",
    "\n",
    "xm,xM = plt.xlim()\n",
    "ym,yM = plt.ylim()\n",
    "\n",
    "XX, YY = np.meshgrid(np.linspace(xm,xM, 100),np.linspace(ym,yM, 100)) \n",
    "\n",
    "## We now form a 10000x2 array of the (x,y) coordiantes for each point by reshaping\n",
    "## the XX and YY matricies and pasting them together. We need to feed a Nx2 vector\n",
    "## into the qda.predict function, otherwise it will think we have too many features.\n",
    "## We can reshape it later to get our grid back\n",
    "\n",
    "grid=np.concatenate([XX.reshape(-1,1),YY.reshape(-1,1)],axis=1)\n",
    "\n",
    "ZZ = clf.predict(grid).reshape(XX.shape)  ## We predict, and reshape back to the origional grid\n",
    "\n",
    "z1 = ZZ == 'M'\n",
    "z2 = ZZ == 'B'\n",
    "\n",
    "plt.plot(XX[z1],YY[z1],',',color=\"C0\")\n",
    "plt.plot(XX[z2],YY[z2],',',color=\"C1\")\n",
    "\n",
    "plt.plot(u,v,label=\"Decision Boundary\",color=\"black\")\n",
    "\n",
    "## We now reset the x and y limits to make sure our view is centered tightly\n",
    "## around the data. \n",
    "\n",
    "plt.xlabel(\"radius_mean\",fontsize=20)\n",
    "plt.ylabel(\"concavity_mean\",fontsize=20)\n",
    "plt.legend(fontsize=15)\n",
    "\n",
    "ax.set_xlim([xm, xM])\n",
    "ax.set_ylim([ym, yM])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation with Sci-Kit Learn\n",
    "\n",
    "We see that logistic regression actually does a bit _worse_ than linear regression. This is probably not surprising, we know that linear regression should perform well when only being compared to the dataset itself. We would expect to gain something if we split the data and tried cross validation. We will use the `train_test_split` library from sci-kit learns `model_selection` library.\n",
    "\n",
    "* `train_test_split(X,y, test_size=, random_state)` Splits the `X` and `y` data into four pieces: `X_train`, `X_test`, `y_train`, and `y_test`. You may split by number or by percentage. You may use `random_state` to specify a random seed so that you can recover the splitting. if need be. \n",
    "\n",
    "It's a good exercise to see how the relative prediction accuracy changes as we change the `test_size` parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[[\"radius_mean\",\"concavity_mean\"]], \n",
    "                                                    y, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "## Liner Regression vis Linear Discriminant Analysis\n",
    "\n",
    "\n",
    "## Quadratic Discriminant Analysis\n",
    "\n",
    "\n",
    "## Logisitic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Utility Functions:\n",
    "\n",
    "You will notice that we have repeated a lot of the same code in the three examples above. Once we've gotten a piece of code running the way we want it it can be very useful to write it up as a function to be used later. In the code below, we will show how to write the graphing of the decision boundary in a function `predict_labels`. Since we may want to compare decision boundaries, we need to pass the function three things: The data `X` and `y`, the classifier, and the axis to be written to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(X,y,ax,pred):\n",
    "    [col0,col1] = X.columns\n",
    "    labels = set(y)\n",
    "    \n",
    "    ## Plot Datapoints By Label\n",
    "    for l in labels:\n",
    "        X_l = X[y==l]\n",
    "        ax.plot(X_l[col0],X_l[col1],'o',label=l,alpha=.5)\n",
    "        \n",
    "    ax.set_xlabel(col0,fontsize=20)\n",
    "    ax.set_ylabel(col1,fontsize=20)\n",
    "    ax.legend(fontsize=15)\n",
    "    \n",
    "    ### Predict on Grid\n",
    "    xm,xM = ax.get_xlim()\n",
    "    ym,yM = ax.get_ylim()\n",
    "    XX, YY = np.meshgrid(np.linspace(xm,xM, 100),np.linspace(ym,yM, 100)) \n",
    "    \n",
    "    grid=np.concatenate([XX.reshape(-1,1),YY.reshape(-1,1)],axis=1)\n",
    "    ZZ = pred.predict(grid).reshape(XX.shape)  ## We predict, and reshape back to the origional grid\n",
    "    z1 = ZZ == 'M'\n",
    "    z2 = ZZ == 'B'\n",
    "    ax.plot(XX[z1],YY[z1],',',color=\"C0\")\n",
    "    ax.plot(XX[z2],YY[z2],',',color=\"C1\")\n",
    "    \n",
    "    ax.set_xlim([xm, xM])\n",
    "    ax.set_ylim([ym, yM])\n",
    "    ax.set_title(type(pred).__name__)\n",
    "    \n",
    "\n",
    "    \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()\n",
    "X = data[[\"radius_mean\",\"texture_mean\"]]\n",
    "clf.fit(X,y)\n",
    "    \n",
    "f, ax = plt.subplots(figsize=(5,5))   \n",
    "predict_labels(X,y,ax,clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Liner Regression vis Linear Discriminant Analysis\n",
    "lda = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "## Quadratic Discriminant Analysis\n",
    "qda = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "qda.fit(X_train, y_train)\n",
    "\n",
    "## Logisitic Regression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "## Plotting:\n",
    "f, axes = plt.subplots(1,3, figsize=(15,5))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, pred in enumerate([lda, qda, clf]):\n",
    "    predict_labels(X_train,y,axes[i],pred)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise:\n",
    "\n",
    "Extend the plotting function above to also provide the scores for each predictor. These scores can be reported in the title, or as an annotation (https://matplotlib.org/tutorials/text/annotations.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel Classification\n",
    "\n",
    "Now that we have some classification and visualization tools under our belt, lets turn to a high dimensional problem: Using linear methods to classify the MNIST (Mixed National Institute of Standards and Technology) dataset. MNIST is essentially the \"Hello World\" of visual machine learning.\n",
    "\n",
    "<table>\n",
    "    <tr><td>\n",
    "        <img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\" width=300px>\n",
    "        </td>\n",
    "        </td><td width=20px>\n",
    "            $$\\Rightarrow$$\n",
    "        </td>\n",
    "        <td width=40px>\n",
    "        <table><tr><td>0</td></tr><tr><td>1</td></tr><tr><td>2</td></tr><tr><td>3</td></tr>\n",
    "        <tr><td>4</td></tr><tr><td>5</td></tr><tr><td>6</td></tr><tr><td>7</td></tr><tr><td>8</td></tr>\n",
    "            <tr><td>9</td></tr>\n",
    "        </table>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Our goal with MNIST will be to correctly predict the number for picture. \n",
    "\n",
    "It's worth taking a look at MNIST's home: http://yann.lecun.com/exdb/mnist/, where they have the current best benchmarks on the dataset (of course reproducibility is required). \n",
    "\n",
    "Alternatively, you can download it from Kaggle https://www.kaggle.com/c/digit-recognizer/data (if you cannot open .gz files) or if you are on Google colab, use \n",
    "\n",
    "`from keras.datasets import mnist`\n",
    "\n",
    "`(x_train, y_train), (x_test, y_test) = mnist.load_data()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "## If your files have been saved locally:\n",
    "\n",
    "#MNIST_train = pd.read_csv(\"MNIST_train.csv\")\n",
    "#MNIST_test = pd.read_csv(\"MNIST_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of the data set consists of a label, and list of 784 pixel values (either 0 to 255), forming $28\\times 28$ pictures . If you downloaded the data locally, you may need to split into training features and labels and recast the data as a numpy array to make it easier to call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(MNIST_train[\"label\"])\n",
    "X_train = np.array(MNIST_train.drop(columns=[\"label\"]))\n",
    "\n",
    "y_test = np.array(MNIST_test[\"label\"])\n",
    "X_test = np.array(MNIST_test.drop(columns=[\"label\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing one of the pictures is simple enough, we just use `.reshape(28,28)` on a row of `X_train` and then use `plt.imshow` to display the pixels of the matrix as black and white. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a 4, and that is what the label tells us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one last step before we get started lets shuffle the data set to makes sure we're not picking up any information from the order. To do this we use `numpy.permutation` to generate a permutation of the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_index = np.random.permutation(42000)\n",
    "X_train = X_train[shuffle_index]\n",
    "y_train = y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some visualizations\n",
    "\n",
    "It's hard to visualize high dimensional data. The visualization of high dimensional data is a whole lab in and of itself, but we can extract some interesting information (or at least some clarifying information!). \n",
    "\n",
    "First, lets find the \"average\" examples of each number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[y_train == 9].mean(0).reshape(28,28), cmap='Greys')\n",
    "\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping through the possible labels, we can construct a grid of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2,5,figsize=(15,5))\n",
    "\n",
    "axes = axes.reshape(-1)\n",
    "\n",
    "for i in range(0,10):\n",
    "    axes[i].imshow(X_train[y_train == i].mean(0).reshape(28,28), cmap='Greys')\n",
    "    axes[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also form the pixel by pixel scatter plot, just to see if there is any structure here. We'll light up two adjacent pixels in the very middle: on the pixels 14 and 15 on row 14:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10,10))\n",
    "for i in range(0,10):\n",
    "    plt.plot(X_train[y_train == i,13,13],X_train[y_train == i,13,14],'o',alpha=.5,label=i)\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's something going on here, but it's not clear what. Maybe if we could project onto the correct dimension this would yield something but as we see the distribution is nontrivial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Our Classifiers: Logistic Regression\n",
    "\n",
    "Lets start by trying to fit using logistic regression. There is nothing new that we need to do, the regression functions treat a large amount of data the same way as they treat a small amount of data. With logistic regression we don't even need to worry about one-hot encoding the labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite good, so on average we're only missclassifying 15% pictures. Given that there is only one correct label and 10 incorrect ones this is a decent result. \n",
    "\n",
    "Remember as well that we have created a real predictor. For example, we can try to predict the 6001'st element of the MNIST data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New predictions\n",
    "\n",
    "Try something yourself: Using MS paint or another program, create a $28\\times 28$ picture with a black background and draw a which number on it. Save the picture as a bitmap in the same directory as the notebook. \n",
    "\n",
    "We can load this picture in with `plt.imread(\"picname.bmp\")` and use `plt.imshow` to display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = plt.imread(\"testpic.png\")\n",
    "plt.imshow(im,cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at the shape of the file, you'll see that it is `im.shape = (28,28,4)`. That means it has 4 channels: Red, Green, Blue and Alpha or RGBA. We've been fitting one channel black and white pictures, so to predict you must extract a single channel of data and reshape it from a matrix into a vector. If the picture is black and white the Red, Green and Blue channels will all contain the same information so we can just extract the zero'th channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im[:,:,0],cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, looking at `im[:,:,0]` we find that while `X_train` has data stored between 0 and 255, `im[:,:,0]` has the background as 1 and the foreground as 0. We need to rescale `im[:,:,0]` to be on the same order as the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did it do? If it's drastically off make sure you're picture is black on white, not white on black. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Our Classifiers: LDA and QDA\n",
    "\n",
    "Lets now compare these to the results for the quadratic and linear discriminant classifiers. First, you should notice that they run significantly faster than regression, and in fact we can crank up the number of training samples quite high. As expected, the more training data points we use the better our testing results are, but although that number shoots upward between 100 and 1000 data points, the rate of change tapers off as we pass 10,000 data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "## Liner Regression vis Linear Discriminant Analysis\n",
    "lda = LinearDiscriminantAnalysis(store_covariance=True)\n",
    "lda.fit(X_train[0:20000].reshape(-1,28*28), y_train[0:20000])\n",
    "print(\"LDA Score: %.3f\"%lda.score(X_test.reshape(-1,28*28),y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "## Quadratic Discriminant Analysis\n",
    "qda = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "qda.fit(X_train[0:10000].reshape(-1,28*28), y_train[0:10000])\n",
    "print(\"QDA Score: %.3f\"%qda.score(X_test.reshape(-1,28*28),y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does each of our classifiers do fitting our handwritten digit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic:\",clf.predict(mypic))\n",
    "print(\"Linear:\",lda.predict(mypic))\n",
    "print(\"Quadratic:\",qda.predict(mypic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "Finally, we will use straight linear regression. Recall our pipeline for linear regression:\n",
    "\n",
    "* Convert the y values to a one-hot vector.\n",
    "* Fit using linear regression.\n",
    "* Predict using argmax\n",
    "\n",
    "You might be surprised to see how much data we can squeeze through the standard linear classifier. You may even be able to train on the whole data set without any slowdown depending on your processor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "N = 40000\n",
    "\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "print(\"The r^2 score on the training data is %.3f\"%(lr.score(X_test.reshape(-1,28*28),y_test_OH)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we understand the score of this model? Is it just completely missclassifying the test data? Lets use `np.argmax` to predict the score on the first image in the training set. Rather annoyingly, we must use\n",
    "\n",
    "`X_test[0].reshape(1, -1)`\n",
    "\n",
    "to reshape the vector into a row vector since numpy returns single vectors as column vectors by default. But then, we're used to all vectors being column vectors unless otherwise stated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lr.predict(X_test[0].reshape(1, -1))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've return the linear predictors for each label, we will use `np.argmax` to return the position of the larges $\\hat{f}_k$. Although by looking we can see it is 1, (remember the indexing starts from 0). We also check the true value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Our Prediction:\", np.argmax(pred))\n",
    "print(\"True Value:\", y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it got the first one correct, what about the first five? Again, we can use `np.argmax`, although we need to specify that we're taking argmax for down the columns by specifying `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First Five Predictions:\", np.argmax(lr.predict(X_test[0:5].reshape(-1,28*28)), axis=1))\n",
    "print(\"First Five True Labels:\", y_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our predictor actually seems to be doing quite well, so what's going on? The answer of course is that it's returning the r^2 score, which is generally going to be horrible on a classification task. A better measure is to use the mean accuracy that the logistic regression, LDA and QDA classes used. Sci-kit learn has build in scores for most loss functions. \n",
    "\n",
    "Loading `accuracy_score` from `sklearn.metrics`, we predict on whole test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predict = np.argmax(lr.predict(X_test.reshape(-1,28*28)),axis=1)\n",
    "\n",
    "acc = accuracy_score(y_test, y_predict)\n",
    "print(\"The accuracy score on the training data is %.3f\"%(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With enough data this is comparable to logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix \n",
    "\n",
    "The mean accuracy is a useful measure of success, but it doesn't give us any granular information. For example, with a mean accuracy of 15% we could be in any of the following scenarios:\n",
    "\n",
    "* For each digit, there's a 15% chance it will be misclassified.\n",
    "* There's an equal split of data among all digits. However, 9's are always misclassified as 4's and 0's are misclassified half the time as 8's. \n",
    "* There's an equal split of data among all digits. However, 9's are always misclassified and 0's are misclassified 50% of the time, but it's always as something random.\n",
    "* 85% of the data is 1's and the classifier is just classifying everything as 1. \n",
    "* Others?\n",
    "\n",
    "This leads to the idea of __precision__ vs __recall__. For a label $k$, let $Tp_k$ be the number of __true positives__, that is the number of items correctly guessed to have label $k$. Let $Fp_k$ be the number of __false positives__, that is the number of items incorrectly guessed to have label $k$.\n",
    "\n",
    "The __precision__ is \n",
    "\n",
    "$$\n",
    "\\textbf{Precision}_k = \\frac{Tp_k}{Tp_k + Fp_k}\\,,\n",
    "$$\n",
    "\n",
    "the proportion items we predicted to be labeled $k$ that actually were. Let $Fn_k$ be the number of __false negatives__, the is the number of items whose true label was $k$ that were incorrectly labeled. The __recall__ is\n",
    "\n",
    "$$\n",
    "\\textbf{Recall}_k = \\frac{Tp_k}{Tp_k + Fn_k}\\,,\n",
    "$$\n",
    "\n",
    "the proportion of items whose true label is $k$ that are labeled correctly. \n",
    "\n",
    "These concepts can be collected into a __Confusion Matrix__. The confusion matrix summarizes how our predictor labeled test data vs the true labeling. \n",
    "\n",
    "We can import the confusion using `from sklearn.metrics import confusion_matrix`. We will then use our linear predictor to predict the labels on the test set, and use `confusion_matrix(y_true,y_predict)` to get a breakdown of how the data is misclassified. The true labeling is along the vertical axis and the guessed labeling is the horizontal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_predict = np.argmax(lr.predict(X_test.reshape(-1,28*28)),axis=1)\n",
    "\n",
    "conf_mx = confusion_matrix(y_test, y_predict)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the number of missclassifications, lets normalize the rows by dividing by the total number of each true label. We can then remove the diagonal and plot a heat map to see where things are getting misclassified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sum = conf_mx.sum(axis=1, keepdims=True)\n",
    "nconf_mx = conf_mx/row_sum\n",
    "np.fill_diagonal(nconf_mx,0)\n",
    "\n",
    "sns.heatmap(nconf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 9's are getting misclassified as 7's, 5's are getting misclassified as 3's and 8's as 1's.  Analyzing the confusion matrix can often tell you what's going right and wrong with your classification. It can also help to look at the individual mistakes. Let's get the index of training sets that contain 5's being misclassified as 3's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ft = (y_test == 5)&(y_predict == 3)\n",
    "\n",
    "f, axes = plt.subplots(5,5,figsize=(5,5))\n",
    "axes = axes.reshape(-1)\n",
    "\n",
    "bads = X_test[ft][0:25]\n",
    "\n",
    "for i in range(0,25):\n",
    "    axes[i].imshow(bads[i].reshape(28,28),cmap=\"Greys\")\n",
    "    axes[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these seem like they should have been correctly classified, but some (like the top right corner) a human would have trouble classifying. That represents a sort of practical upper bound, there are many problems on which 100% accuracy is out of reach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems:\n",
    "\n",
    "### Problem 1: Gender Recognition by Voice\n",
    "\n",
    "From the description file at https://data.world/ml-research/gender-recognition-by-voice:\n",
    "\n",
    "In order to analyze gender by voice and speech, a training database was required. A database was built using thousands of samples of male and female voices, each labeled by their gender of male or female. Voice samples were collected from the following resources:\n",
    "\n",
    "*  [The Harvard-Haskins Database of Regularly-Timed Speech](http://nsi.wegall.net/)\n",
    "*  Telecommunications & Signal Processing Laboratory (TSP) Speech Database at McGill University\n",
    "*  [VoxForge Speech Corpus](http://www.repository.voxforge1.org/downloads/SpeechCorpus/Trunk/Audio/Main/8kHz_16bit/)\n",
    "*  [Festvox CMU_ARCTIC Speech Database at Carnegie Mellon University](http://festvox.org/cmu_arctic/dbs_awb.html)\n",
    "\n",
    "Each voice sample is stored as a .WAV file, which is then pre-processed for acoustic analysis using the specan function from the WarbleR R package. Specan measures 22 acoustic parameters on acoustic signals for which the start and end times are provided.\n",
    "\n",
    "The output from the pre-processed WAV files were saved into a CSV file, containing 3168 rows and 21 columns (20 columns for each feature and one label column for the classification of male or female). You can download the pre-processed dataset in CSV format, using the link above\n",
    "Acoustic Properties Measured\n",
    "\n",
    "The following acoustic properties of each voice are measured:\n",
    "\n",
    "*    __duration:__ length of signal\n",
    "*    __meanfreq:__ mean frequency (in kHz)\n",
    "*    __sd:__ standard deviation of frequency\n",
    "*    __median:__ median frequency (in kHz)\n",
    "*    __Q25:__ first quantile (in kHz)\n",
    "*    __Q75:__ third quantile (in kHz)\n",
    "*    __IQR:__ interquantile range (in kHz)\n",
    "*    __skew:__ skewness (see note in specprop description)\n",
    "*    __kurt:__ kurtosis (see note in specprop description)\n",
    "*    __sp.ent:__ spectral entropy\n",
    "*    __sfm:__ spectral flatness\n",
    "*    __mode:__ mode frequency\n",
    "*    __centroid:__ frequency centroid (see specprop)\n",
    "*    __peakf:__ peak frequency (frequency with highest energy)\n",
    "*    __meanfun:__ average of fundamental frequency measured across acoustic signal\n",
    "*    __minfun:__ minimum fundamental frequency measured across acoustic signal\n",
    "*    __maxfun:__ maximum fundamental frequency measured across acoustic signal\n",
    "*    __meandom:__ average of dominant frequency measured across acoustic signal\n",
    "*    __mindom:__ minimum of dominant frequency measured across acoustic signal\n",
    "*    __maxdom:__ maximum of dominant frequency measured across acoustic signal\n",
    "*    __dfrange:__ range of dominant frequency measured across acoustic signal\n",
    "*    __modindx:__ modulation index. Calculated as the accumulated absolute difference between adjacent measurements of fundamental frequencies divided by the frequency range\n",
    "\n",
    "The gender of the speaker is given in the __label__ column. \n",
    "\n",
    "Note, the features for duration and peak frequency (peakf) were removed from training. Duration refers to the length of the recording, which for training, is cut off at 20 seconds. Peakf was omitted from calculation due to time and CPU constraints in calculating the value. In this case, all records will have the same value for duration (20) and peak frequency (0).\n",
    "\n",
    "Load file using the code below. \n",
    "\n",
    "#### Question 1:\n",
    "\n",
    "Which two features are most indicative of gendered voice?\n",
    "\n",
    "#### Question 2:\n",
    "\n",
    "Preform Linear Regression, Logistic Regression, and Quadratic Discriminant Analysis on the features, graphing the resulting fits. How does the two feature fit compare to the fit on all features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/tipthederiver/Math-7243-2020/master/Datasets/GenderedVoice/voice.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: MRI Data\n",
    "\n",
    "The dementia level for the Oasis 1 MRI dataset is based on a patient assessment. As a result, it is not clear whether the levels of 0, .5, 1 and 2 should actually be understood as meaningfully numeric, or if they in fact are categorical labels. \n",
    "\n",
    "In this problem we want to treat them as categorical. However, we would also like to construct a slightly larger dataset, as we have seen that for images our 700 may not be sufficient. To construct a larger dataset we will again down sample the images, however this time we will use the down sampling to expand the dataset instead of throwing data away. After fixing a down sample rate $D$, we will construct one image out of the pixels $nD$, for $n = 1,2,\\ldots, $. We will also construct $n D+i$, for $i = 1,\\ldots, D$. This way, by down sampling with a rate $D$, we construct $D$ more pictures. \n",
    "\n",
    "__Note:__ It is very import that we perform the train test split _before_ we expand the dataset through down sampling. If not, we are effectively training on the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "file_dir = 'C:/PATH_TO_IMAGE_DIRECTORY/'\n",
    "file_dir = 'C:/Users/Admin/Downloads/Student Data/MRILargeSlices/'\n",
    "\n",
    "labels = pd.read_csv(file_dir + 'labels.csv')\n",
    "display(labels)\n",
    "y = labels.CDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros([702, 36608])\n",
    "\n",
    "for n, file_name in enumerate(labels.Filename):\n",
    "    data[n,:] = np.mean(matplotlib.image.imread(file_dir + file_name),axis=2).reshape(-1)\n",
    "\n",
    "    \n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, y, test_size=0.2, random_state=0)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to sample the data array using the `data[start:stop:step]` slice paradigm. This means we are taking elements of the array `data` starting at `start`, ending at `stop` with step `step`. This is why previously `data[::DS]` down sampled at a rate of DS. For example, \n",
    "\n",
    "    lst = list(range(165)); lst[6::10]\n",
    "    \n",
    "returns\n",
    "\n",
    "    [6, 16, 26, 36, 46, 56, 66, 76, 86, 96, 106, 116, 126, 136, 146, 156]\n",
    "\n",
    "We need to create two new arrays, one of shape $[561\\times DS, 36608/DS]$ containing the down sampled data, and one of shape $[561\\times DS]$ containing the labels. The for each of the $N_{train}$ images in the training array, we need to create $DS$ new down sampled images, with the downsample starting from $i$:\n",
    "\n",
    "`Xds_train[n+i, :] = X_train[i::DS]`\n",
    "\n",
    "This will split our images into DS down sampled images. We then need to be sure to save out the appropriate label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = 8             # Downsample rate, must be a multiple of 36608\n",
    "\n",
    "N_train = y_train.shape[0]  # The length of the training data\n",
    "\n",
    "if 36608/DS % 1 > 0:\n",
    "    print(\"Downsample rate is not a multiple of 36608\")\n",
    "    DS = 1\n",
    "    im_size = 36608\n",
    "else:\n",
    "    im_size = int(36608/DS)\n",
    "\n",
    "Xds_train = np.zeros([N_train*DS, im_size])\n",
    "yds_train = np.zeros([N_train*DS, im_size])\n",
    "    \n",
    "for n in range(N_train):\n",
    "    for i in range(DS):\n",
    "        Xds_train[n+i,:] = X_train[n,i::DS]\n",
    "        yds_train[n+i] = y[n]\n",
    "        \n",
    "print(Xds_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "\n",
    "Based on the code above, downsample the test data in the same way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "\n",
    "Perform LDA, QDA, Logistic Regression and Categorical Linear Regression on the down sampled Oasis 1 dataset. How do these compare to linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
