{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Methods in Linear Regression\n",
    "\n",
    "## Problems:\n",
    "\n",
    "### Problem 1: Bootstrapping a Confidence Interval\n",
    "\n",
    "If we don't have a formula for the confidence interval of a statistic, we can often estimate it by sampling from out data set many times, computing the statistic of interest, and then plotting the distribution. This is known as __bootstrapping__ the confidence interval, since you're using the data to make estimates about your fits, effectively pulling yourself up by your bootstraps. In this problem, we will see how to boot strap the confidence interval for the $\\beta$ parameters in the linear fit. \n",
    "\n",
    "Lets return to the one variable examples of fitting the sales price to the first floor square footage __1stFlrSF__. Using a for loop, compute $\\beta_0$ and $\\beta_1$ 1000 times for samples of size $N = 1436$ _with replacement_ and store their results in vectors, as in the code below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "\n",
    "beta0 = np.zeros(N)\n",
    "beta1 = np.zeros(N)\n",
    "\n",
    "for i in range(N):\n",
    "    ## Compute beta0 and beta1, using linear algebra, sklearn, or scipy\n",
    "    beta0[i] = \n",
    "    beta1[i] = \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Turn in__\n",
    "\n",
    "1. Plot a histogram of $\\beta_0$ and $\\beta_1$. \n",
    "2. Using `beta0.sort()`, sort the values and find the interval containing the middle 950 values. This is the bootstrap 95% confidence interval. \n",
    "3. Using the formulas from Lecture 3, compute the confidence interval using the $z$-score. Remember that here you use all of the training data. Compare your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Linear Methods on High Dimensional Data\n",
    "\n",
    "Perform ridge regression and lasso regression on the MRI Slices dataset on blackboard. You should follow the __Loading the Viewing MRI Slices__ notebook, eventually loading all slices into Python as a data matrix, with all picture dimensions flattened. The text and code for that process has been reproduced below.\n",
    "\n",
    "We want to fit the MRI Slices data to the label __CDR__ in the labels data.\n",
    "\n",
    "\n",
    "__Turn in__: \n",
    "\n",
    "1. Given the train-test split with seed $255$, what is the best $\\alpha$ value for pure Ridge Regression? Justify your answer. \n",
    "2. Given the train-test split with seed $255$, what is the best $\\lambda$ value for pure Lasso Regression? Justify your answer. \n",
    "3. (Bonus) What is the best $(\\alpha,\\lambda)$ value for elastic net regression?\n",
    "\n",
    "You may set the downsample rate to higher you are unable to compute the linear model.\n",
    "\n",
    "### Load MRI All Files\n",
    "\n",
    "To load all of the files into an array we need to be able to search through the directory. Luckily, this is easy to do using the labels file, since each file name is stored there. We just need to loop through the __Filename__ column in the `labels` dataset and load them into an array one by one. There are 702 files in total. \n",
    "\n",
    "With the array there are two ways we can load them in: First, we can load them into a $702\\times 176 \\times 208$ array, which is the best option if we care about the 2D structure. However for algorithms like linear regression that done see the 2D structure, we may want to flatten the images to a $702\\times 36608$ array (note that $36608 = 176 \\times 208$). Its easy enough two switch back and forth between the two array structures later. We will start with the flattened array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "file_dir = 'C:/PATH_TO_IMAGE_DIRECTORY/'\n",
    "\n",
    "labels = pd.read_csv(file_dir + 'labels.csv')\n",
    "display(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = 8             # Downsample rate, must be a multiple of 36608\n",
    "\n",
    "if 36608/DS % 1 > 0:\n",
    "    print(\"Downsample rate is not a multiple of 36608\")\n",
    "    DS = 1\n",
    "    im_size = 36608\n",
    "else:\n",
    "    im_size = int(36608/DS)\n",
    "\n",
    "\n",
    "data = np.zeros([702, im_size])\n",
    "\n",
    "for i, file_name in enumerate(labels.Filename):\n",
    "    img = np.mean(matplotlib.image.imread(file_dir + file_name),axis=2).reshape(-1)\n",
    "    data[i,:] = img[::DS]            # Downsample the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
