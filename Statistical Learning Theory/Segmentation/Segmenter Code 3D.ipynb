{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Segmentation using U-Net\n",
    "\n",
    "To do:\n",
    "\n",
    "* Download an unzip the files to the HD\n",
    "* Open files, preprocess data, save to drive. \n",
    "* Load files into a batch readable object.\n",
    "* Set up and train network.\n",
    "* Visualize Results\n",
    "\n",
    "First, upload the .zip containing the image and segments to the instance, then run from the command line:\n",
    "\n",
    "    sudo apt-get install unzip\n",
    "    unzip Segmented\\ Numpy\\ Data.zip -d FullMRI\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from ipywidgets import IntProgress\n",
    "from ipywidgets import HBox\n",
    "from ipywidgets import Label\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "img_folder = \"FullMRI/Segmented Numpy Data\"\n",
    "out_folder = \"Downsampled Two Numpy Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D: Open files, preprocess data, save to drive. \n",
    "\n",
    "This code expects a folder containing files of a certain form. We may want to modify it in the future to draw from a table of files, but as long as we keep the formatting consistent this should be fine. \n",
    "\n",
    "* Input: An input folder an (empty) output folder. Input folder should contain image files named \"...MP.npz\" and label segment files named \"...MPseg.npz\".\n",
    "\n",
    "* Output: None. \n",
    "\n",
    "For each IMG file, function will perform a 2x2x2-fold downsampling and output 8 files named \"...MP<N>.npz\" and \"...MPseg<N>.npz\" where \"<N>\" are the numbers 0 to 7. \n",
    "    \n",
    "The code also allows you to specify a crop to cut out the middle. Following the project, we will use\n",
    "    \n",
    "     x-axis (42,121)\n",
    "     y-axis (40,161)\n",
    "     z-axis (32,134)\n",
    "    \n",
    "of each image, as determined in the project. \n",
    "    \n",
    "The data will be saved in a directory structure that seperates the training and testing data:\n",
    "    \n",
    "    train/img\n",
    "    train/seg\n",
    "    test/img\n",
    "    test/seg\n",
    "    \n",
    "Progress bar code taken from \n",
    "    \n",
    "https://stackoverflow.com/questions/38861829/how-do-i-implement-a-progress-bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some of the train test data after is has been split\n",
    "\n",
    "def display_train_test(out_folder):\n",
    "    f, ax = plt.subplots(2,4,figsize=(10,5))\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    train_files = [file for file in os.listdir(out_folder + \"/train/imgs/\") if file.endswith(\".npz\")]\n",
    "    test_files = [file for file in os.listdir(out_folder + \"/test/imgs/\") if file.endswith(\".npz\")]\n",
    "\n",
    "    tt = \"/train\"\n",
    "\n",
    "    for i in range(8):\n",
    "        if(i>5):\n",
    "            tt = '/test'\n",
    "            file = test_files[np.random.randint(len(test_files))]\n",
    "        else:\n",
    "            file = train_files[np.random.randint(len(train_files))]\n",
    "        # Pick a random file\n",
    "\n",
    "        print(out_folder + tt + \"/imgs/\" + file)\n",
    "        img = np.load(out_folder + tt + \"/imgs/\" + file)['arr_0']\n",
    "        seg = np.load(out_folder + tt + \"/segs/\" + file)['arr_0']\n",
    "        \n",
    "        bounds = get_bounds(seg)\n",
    "        sl = int(np.round((bounds[0][0] + bounds[1][0])/2))\n",
    "        \n",
    "        masked = np.ma.masked_array(seg[sl,:,:], seg[sl,:,:]==0.0)\n",
    "        ax[i].imshow(img[sl,:,:],cmap=\"Greys\")\n",
    "        ax[i].imshow(masked)\n",
    "        ax[i].set_title(tt[1:])\n",
    "        \n",
    "#display_train_test(out_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the bounding box for a segment\n",
    "\n",
    "def get_bounds(seg):\n",
    "    M = (np.max(np.where(seg)[0]),np.max(np.where(seg)[1]),np.max(np.where(seg)[2]))\n",
    "    m = (np.min(np.where(seg)[0]),np.min(np.where(seg)[1]),np.min(np.where(seg)[2]))\n",
    "\n",
    "    return[m,M]\n",
    "    \n",
    "#get_bounds(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from ipywidgets import IntProgress\n",
    "from ipywidgets import HBox\n",
    "from ipywidgets import Label\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "def creatDir(new_dir):\n",
    "    if not os.path.isdir(new_dir):\n",
    "        try:\n",
    "            os.mkdir(new_dir)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % new_dir)\n",
    "        else:\n",
    "            print (\"Successfully created the directory %s \" % new_dir)\n",
    "    \n",
    "\n",
    "def downsample3D(img_folder, out_folder, sample = True, split = .8, downsample = 2, crop = None):\n",
    "    # Load all of the base filenames, ignoring all other files in directory\n",
    "    \n",
    "    base_files = [file for file in os.listdir(img_folder) if file.endswith(\"MR.npz\")]\n",
    "    \n",
    "    # Check if the output directories exists. If not, create it. \n",
    "    \n",
    "    creatDir(out_folder)\n",
    "    creatDir(out_folder + \"/train\")\n",
    "    creatDir(out_folder + \"/test\")\n",
    "    creatDir(out_folder + \"/train/imgs\")\n",
    "    creatDir(out_folder + \"/train/segs\")\n",
    "    creatDir(out_folder + \"/test/imgs\")\n",
    "    creatDir(out_folder + \"/test/segs\")\n",
    "            \n",
    "    # Set up progress bar.\n",
    "    \n",
    "    f = IntProgress(min=0, max=len(base_files))\n",
    "    l = Label(\"Loading File\")\n",
    "    H = HBox([f, l])\n",
    "    display(H) # display the bar and label\n",
    "    \n",
    "    # Set up the output folders\n",
    "    \n",
    "    out_fol_img = out_folder + \"/train/imgs/\"\n",
    "    out_fol_seg = out_folder + \"/train/segs/\"\n",
    "    tt = \"Train: \" # The label for the progress bar\n",
    "    \n",
    "    # If crop is not None, get the crop range:\n",
    "    if not crop:\n",
    "        a1 = b1 = c1 = 0\n",
    "        (a2,b2,c2) = np.load(img_folder + \"/\" + base_files[0])['arr_0'].shape\n",
    "    else:\n",
    "        (a1,a2,b1,b2,c1,c2) = crop\n",
    "        \n",
    "    print(\"Cropping to \", a1,a2,b1,b2,c1,c2)\n",
    "    \n",
    "    # For each file, load both the file and segmentation in. Downsample both and output.\n",
    "    \n",
    "    ds = downsample\n",
    "    for n, file in enumerate(base_files):\n",
    "        img = np.load(img_folder + \"/\" + file)['arr_0'][a1:a2,b1:b2,c1:c2]\n",
    "        seg = np.load(img_folder + \"/\" + file[:-4] + \"seg.npz\")['arr_0'][a1:a2,b1:b2,c1:c2]\n",
    "        \n",
    "\n",
    "        if (n+1) > len(base_files)*split:\n",
    "            out_fol_img = out_folder + \"/test/imgs/\"\n",
    "            out_fol_seg = out_folder + \"/test/segs/\"\n",
    "            tt = \"Test: \"\n",
    "            \n",
    "        for i in range(ds):\n",
    "            for j in range(ds):\n",
    "                for k in range(ds):\n",
    "                    N = str(i + ds*j + (ds**2)*k)\n",
    "                    ds_img = img[i::ds,j::ds,k::ds]\n",
    "                    ds_seg = seg[i::ds,j::ds,k::ds]\n",
    "\n",
    "                    np.savez_compressed(out_fol_img + file[:-4] + N + \".npz\", ds_img)\n",
    "                    np.savez_compressed(out_fol_seg + file[:-4] + N + \".npz\", ds_seg)\n",
    "                    \n",
    "        f.value += 1 # signal to increment the progress bar\n",
    "        l.value = tt + file\n",
    "        \n",
    "      \n",
    "    # Display a sample output if requested\n",
    "    if sample:            \n",
    "        display_train_test(out_folder)\n",
    "                    \n",
    "    ## Summerize preproccesing info\n",
    "    \n",
    "    f = ds**3\n",
    "    \n",
    "    print(\"Train Images:\", int(f*np.floor(len(base_files)*split)))\n",
    "    print(\"Test Images:\", int(f*(len(base_files) - np.floor(len(base_files)*split))))\n",
    "    print(\"Dimensions:\", ds_img.shape)\n",
    "    \n",
    "    return ds_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample3D(img_folder, out_folder, crop = (42,122,41,161,24,144), downsample=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images into batch loading object\n",
    "\n",
    "The code below seems to be some sort of standard example? I've found it copied and pasted all of the fucking web with each author taking extreme personal credit for it...\n",
    "\n",
    "One example source for this is here:\n",
    "\n",
    "https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "\n",
    "This code also flips horizontally, doubling the dataset. You can play around with the batch size if you want but I found that a small batch size works better here,  like around 1 or 2. If you're on a server you can try to bump it up to like 16 or 32. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, folder, batch_size=2, dim=(88, 104, 88), shuffle=True, tt = \"train\"):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.tt = tt\n",
    "        self.folder = folder + \"/\" + tt\n",
    "        \n",
    "        ## Get list of applicable filenames:\n",
    "        self.files = [file for file in os.listdir(self.folder + \"/segs\") if file.endswith(\".npz\")]\n",
    "        print(len(self.files), \"Files Found.\")\n",
    "        self.list_IDs = list(range(len(self.files)))\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty(((self.batch_size)*2, *self.dim,1))\n",
    "        y = np.empty(((self.batch_size)*2, *self.dim,1))\n",
    "        L = self.batch_size\n",
    "\n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store image and horizontal flip\n",
    "            X[i,:,:,:,0] = np.load(self.folder + \"/imgs/\" + self.files[ID])['arr_0']\n",
    "            X[L + i,:,:,:,0] = np.flip(np.load(self.folder + \"/imgs/\" + self.files[ID])['arr_0'],2)\n",
    "\n",
    "            # Store segment and horizontal flip\n",
    "            y[i,:,:,:,0] = np.load(self.folder + \"/segs/\" + self.files[ID])['arr_0']\n",
    "            y[L + i,:,:,:,0] = np.flip(np.load(self.folder + \"/segs/\" + self.files[ID])['arr_0'],2)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(folder=out_folder, tt = \"train\", dim=(40, 60, 60))\n",
    "testing_generator = DataGenerator(folder=out_folder, tt = \"test\", dim=(40, 60, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = training_generator.__getitem__(0)\n",
    "\n",
    "N = 0\n",
    "sl = 20\n",
    "\n",
    "masked = np.ma.masked_array(y[N,sl,:,:,0], y[N,sl,:,:,0]==0.0)\n",
    "plt.imshow(X[N,sl,:,:,0],cmap=\"Greys\")\n",
    "plt.imshow(masked) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up and train network\n",
    "\n",
    "This code is taken from the Project .ipython, tweaked a bit to get it to work on Windows 10 with tf2. There's a little bit on non-semetricness here but I'm willing to roll with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D,Conv3D,Conv2DTranspose,MaxPooling3D,UpSampling3D\n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import concatenate \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import ZeroPadding3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (40, 60, 60,1)\n",
    "\n",
    "inputs = Input(input_size)\n",
    "conv1 = Conv3D(32, 3, padding = 'same')(inputs)\n",
    "conv1 = BatchNormalization()(conv1)\n",
    "conv1 = Activation('relu')(conv1)\n",
    "conv1 = Conv3D(32, 3, padding = 'same')(conv1)\n",
    "conv1 = BatchNormalization()(conv1)\n",
    "conv1 = Activation('relu')(conv1)\n",
    "\n",
    "\n",
    "pool1 = MaxPooling3D(pool_size=(2, 2, 2))(conv1)\n",
    "conv2 = Conv3D(64, 3, padding = 'same')(pool1)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = Activation('relu')(conv2)\n",
    "conv2 = Conv3D(64, 3, padding = 'same')(conv2)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = Activation('relu')(conv2)\n",
    "\n",
    "\n",
    "pool2 = MaxPooling3D(pool_size=(2, 2, 2))(conv2)\n",
    "conv3 = Conv3D(128, 3, padding = 'same')(pool2)\n",
    "conv3 = BatchNormalization()(conv3)\n",
    "conv3 = Activation('relu')(conv3)\n",
    "conv3 = Conv3D(128, 3, padding = 'same')(conv3)\n",
    "conv3 = BatchNormalization()(conv3)\n",
    "conv3 = Activation('relu')(conv3)\n",
    "drop3 = Dropout(0.5)(conv3)\n",
    "\n",
    "\n",
    "pool3 = MaxPooling3D(pool_size=(2, 2, 2))(drop3)\n",
    "conv4 = Conv3D(64, 3, padding = 'same')(pool3)\n",
    "conv4 = BatchNormalization()(conv4)\n",
    "conv4 = Activation('relu')(conv4)\n",
    "conv4 = Conv3D(64, 3, padding = 'same')(conv4)\n",
    "conv4 = BatchNormalization()(conv4)\n",
    "conv4 = Activation('relu')(conv4)\n",
    "drop4 = Dropout(0.5)(conv4)\n",
    "\n",
    "# This line needs to be added for the downsampled example, it should be removed for the full sized img. \n",
    "padd = ZeroPadding3D(((0,0),(0,1),(0,1)))(UpSampling3D(size = (2,2,2))(drop4))\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "\n",
    "up5 = Conv3D(64, 3, padding = 'same')(padd)\n",
    "up5 = BatchNormalization()(up5)\n",
    "up5 = Activation('relu')(up5)\n",
    "merge5 = concatenate([conv3,up5], axis = 4)\n",
    "conv5 = Conv3D(64, 3, padding = 'same')(merge5)\n",
    "conv5 = BatchNormalization()(conv5)\n",
    "conv5 = Activation('relu')(conv5)\n",
    "\n",
    "up6 = Conv3D(32, 2, padding = 'same')(UpSampling3D(size = (2,2,2))(conv5))\n",
    "up6 = BatchNormalization()(up6)\n",
    "up6 = Activation('relu')(up6)\n",
    "merge6 = concatenate([conv2,up6], axis = 4)\n",
    "conv6 = Conv3D(32, 3, padding = 'same')(merge6)\n",
    "conv6 = BatchNormalization()(conv6)\n",
    "conv6 = Activation('relu')(conv6)\n",
    "conv6 = Conv3D(32, 3, padding = 'same')(conv6)\n",
    "conv6 = BatchNormalization()(conv6)\n",
    "conv6 = Activation('relu')(conv6)\n",
    "\n",
    "up7 = Conv3D(16, 3, padding = 'same')(UpSampling3D(size = (2,2,2))(conv6))\n",
    "up7 = BatchNormalization()(up7)\n",
    "up7 = Activation('relu')(up7)\n",
    "\n",
    "merge7 = concatenate([conv1,up7], axis = 4)\n",
    "conv7 = Conv3D(16, 3, padding = 'same')(merge7)\n",
    "conv7 = BatchNormalization()(conv7)\n",
    "conv7 = Activation('relu')(conv7)\n",
    "\n",
    "conv7 = Conv3D(16, 3, padding = 'same')(conv7)\n",
    "conv7 = BatchNormalization()(conv7)\n",
    "conv7 = Activation('relu')(conv7)\n",
    "\n",
    "conv7 = Conv3D(2, 3, padding = 'same')(conv7)\n",
    "conv7 = BatchNormalization()(conv7)\n",
    "conv7 = Activation('relu')(conv7)\n",
    "\n",
    "conv8 = Conv3D(1, 1, activation = 'sigmoid')(conv7)\n",
    "\n",
    "model = Model(inputs, conv8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "##IoU loss\n",
    "def iou_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(K.abs(y_true_f*y_pred_f))\n",
    "    union = K.sum(y_true_f)+K.sum(y_pred_f) - intersection\n",
    "    score = (intersection + smooth)/(union + smooth)\n",
    "    return score\n",
    "\n",
    "def iou_loss(y_true,y_pred):\n",
    "    loss = 1- iou_coeff(y_true,y_pred)\n",
    "    return loss\n",
    "\n",
    "def bce_iou_loss(y_true,y_pred):\n",
    "    loss = binary_crossentropy(y_true,y_pred) + iou_loss(y_true,y_pred)\n",
    "    return loss\n",
    "\n",
    "import ipyvolume as ipv\n",
    "\n",
    "def compared_segments(y_true,y_pred):\n",
    "    loss_summary = [\n",
    "        ('IoU Coefficient',iou_coeff(y_true,y_pred)),\n",
    "        ('IoU Loss',iou_loss(y_true,y_pred)),\n",
    "        ('Binary Crossentropy IoU',bce_iou_loss(y_true,y_pred)),\n",
    "        ('DICE Coefficient',dice_coeff(y_true,y_pred)),\n",
    "        ('DICE Loss',dice_loss(y_true,y_pred)),\n",
    "        ('Binary Crossentropy DICE',bce_dice_loss(y_true,y_pred))\n",
    "    ]\n",
    "    return loss_summary\n",
    "\n",
    "##visualize two segments using ipyvolume\n",
    "import ipyvolume as ipv\n",
    "def compare_segments(y_true,y_pred):\n",
    "    ipv.figure()\n",
    "    ipv.volshow(y_true)\n",
    "    ipv.volshow(y_pred)\n",
    "    ipv.show()\n",
    "\n",
    "    \n",
    "model.compile(optimizer = Adam(lr = 1e-2), loss = bce_dice_loss, metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "\n",
    "LearningRateScheduler(1e-5)\n",
    "\n",
    "epochs = 2\n",
    "filepath = \"model_{epoch:03d}-{loss:.4f}.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, mode='min')\n",
    "csv_logger = CSVLogger(\"model_history_log.csv\", append=True)\n",
    "\n",
    "history = model.fit(training_generator,\n",
    "                    epochs=epochs, \n",
    "                    verbose=1,\n",
    "                    validation_data=testing_generator,callbacks=[checkpoint, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations:\n",
    "Test the model (this should evautaully become a callback function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = testing_generator.__getitem__(0)\n",
    "y_pred = model.predict(X)\n",
    "yy = y_pred[0,:,:,:,0]\n",
    "zz = y[0,:,:,:,0]\n",
    "\n",
    "print(np.sum(yy))\n",
    "print(np.sum(zz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's having trouble pulling its predictions above .5 but we can get some idea of whats being predicted by looking at the results above .4. These are almost certinly the result of just averaging the final segmented models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_pred[0,20,:,:,0]>.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m47",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m47"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
